"""
build_exe.py
─────────────────────────────────────────────────────────────────
Builds a standalone Windows .exe using PyInstaller.

Usage:
  python build_exe.py              # full build
  python build_exe.py --test       # test that exe runs
  python build_exe.py --clean      # wipe build artefacts
"""
import os
# Fix: Windows OpenMP conflict (libiomp5md.dll)
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import argparse
import shutil
import subprocess
import sys
from pathlib import Path

ROOT   = Path(__file__).parent
DIST   = ROOT / "dist"
BUILD  = ROOT / "build"
SPEC   = ROOT / "voice_assistant.spec"

# ── Spec file template ────────────────────────────────────────────────────────
SPEC_CONTENT = """\
# -*- mode: python ; coding: utf-8 -*-
# Auto-generated by build_exe.py
# Target: Python 3.10 · Windows 10/11

import sys
from pathlib import Path

ROOT = Path(SPECPATH)

block_cipher = None

a = Analysis(
    [str(ROOT / 'src' / 'assistant.py')],
    pathex=[str(ROOT / 'src')],
    binaries=[],
    datas=[
        # Config and data files
        (str(ROOT / 'config.yaml'),  '.'),
        (str(ROOT / 'data'),         'data'),
        # Pre-built model files (downloaded by download_models.py)
        (str(ROOT / 'models'),       'models'),
    ],
    hiddenimports=[
        # faster-whisper / ctranslate2
        'faster_whisper',
        'ctranslate2',
        # sentence-transformers
        'sentence_transformers',
        'sentence_transformers.models',
        'sentence_transformers.losses',
        # FAISS
        'faiss',
        'faiss.swigfaiss',
        # Audio
        'webrtcvad',
        'sounddevice',
        'soundfile',
        '_sounddevice',
        # PyTorch (CPU-only)
        'torch',
        'torch.nn',
        'torch.nn.functional',
        'transformers',
        'tokenizers',
        'huggingface_hub',
        # System / utils
        'psutil',
        'psutil._pswindows',
        'rich',
        'rich.console',
        'rich.panel',
        'loguru',
        'yaml',
        'numpy',
        'numpy.core._multiarray_umath',
        'scipy',
        'scipy.spatial',
        'sklearn',
        'sklearn.metrics',
    ],
    hookspath=[],
    hooksconfig={},
    runtime_hooks=[],
    # Trim unused heavy packages to reduce .exe size
    excludes=[
        'matplotlib', 'IPython', 'jupyter', 'notebook',
        'PIL.ImageTk', 'tkinter', '_tkinter',
        'torch.cuda', 'torch.distributed',
        'torchvision.io.video',
    ],
    win_no_prefer_redirects=False,
    win_private_assemblies=False,
    cipher=block_cipher,
    noarchive=False,
)

# Collect all DLLs that sounddevice needs on Windows
from PyInstaller.utils.hooks import collect_dynamic_libs
a.binaries += collect_dynamic_libs('sounddevice')

pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)

exe = EXE(
    pyz,
    a.scripts,
    [],
    exclude_binaries=True,
    name='VoiceAssistant',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=True,            # UPX compression (install UPX separately for smaller .exe)
    console=True,        # Keep console window so user sees transcription output
    disable_windowed_traceback=False,
    argv_emulation=False,
    target_arch=None,
    codesign_identity=None,
    entitlements_file=None,
    icon=None,
    # Windows manifest: request audio device access
    uac_admin=False,
)

coll = COLLECT(
    exe,
    a.binaries,
    a.zipfiles,
    a.datas,
    strip=False,
    upx=True,
    upx_exclude=['vcruntime140.dll', 'msvcp140.dll'],  # never compress VC++ runtimes
    name='VoiceAssistant',
)
"""


def clean():
    """Remove build artefacts."""
    for path in [DIST, BUILD, SPEC]:
        if path.exists():
            if path.is_dir():
                shutil.rmtree(path)
            else:
                path.unlink()
            print(f"Removed: {path}")


def build():
    """Run the full PyInstaller build."""
    print("=" * 60)
    print("  Voice Assistant – Windows Executable Builder")
    print("=" * 60)

    # ── Step 1: Pre-download models so they can be bundled ────────────────
    print("\n[1/4] Downloading models (if not already cached)…")
    _ensure_models()

    # ── Step 2: Write spec file ───────────────────────────────────────────
    print("\n[2/4] Writing PyInstaller spec file…")
    SPEC.write_text(SPEC_CONTENT)
    print(f"  Wrote: {SPEC}")

    # ── Step 3: Run PyInstaller ───────────────────────────────────────────
    print("\n[3/4] Running PyInstaller…")
    cmd = [
        sys.executable, "-m", "PyInstaller",
        "--noconfirm",
        "--clean",
        str(SPEC),
    ]
    result = subprocess.run(cmd, cwd=str(ROOT))
    if result.returncode != 0:
        print("\n[ERROR] PyInstaller build failed!")
        sys.exit(1)

    # ── Step 4: Verify output ─────────────────────────────────────────────
    print("\n[4/4] Verifying output…")
    exe = DIST / "VoiceAssistant" / "VoiceAssistant.exe"
    if not exe.exists():
        # Linux / Mac: no .exe
        exe = DIST / "VoiceAssistant" / "VoiceAssistant"

    if exe.exists():
        size_mb = exe.stat().st_size / 1_000_000
        print(f"\n  ✓ Build successful!")
        print(f"  Executable : {exe}")
        print(f"  Size       : {size_mb:.1f} MB")
    else:
        print(f"\n  ✗ Executable not found at expected location: {exe}")

    print(f"\n  Distribution folder: {DIST / 'VoiceAssistant'}")
    print("  Copy this folder to any Windows machine – no Python needed!\n")


def _ensure_models():
    """Pre-download STT model and embedding model to the models/ directory."""
    import yaml

    cfg_path = ROOT / "config.yaml"
    with open(cfg_path) as f:
        cfg = yaml.safe_load(f)

    model_size = cfg["stt"]["model_size"]
    model_dir  = ROOT / cfg["stt"]["model_dir"]
    model_dir.mkdir(parents=True, exist_ok=True)

    # Download Whisper model
    try:
        from faster_whisper import WhisperModel
        print(f"  Downloading Whisper '{model_size}' to {model_dir}…")
        WhisperModel(model_size, device="cpu", download_root=str(model_dir))
        print("  ✓ Whisper model ready")
    except ImportError:
        print("  ! faster-whisper not installed, skipping model download")

    # Download embedding model
    emb_model = cfg["rag"]["embedding_model"]
    try:
        from sentence_transformers import SentenceTransformer
        emb_dir = ROOT / "models" / "embeddings"
        emb_dir.mkdir(parents=True, exist_ok=True)
        print(f"  Downloading embedding model '{emb_model}'…")
        SentenceTransformer(emb_model, cache_folder=str(emb_dir))
        print("  ✓ Embedding model ready")
    except ImportError:
        print("  ! sentence-transformers not installed, skipping")


def test_exe():
    """Quick smoke test of the built executable."""
    exe = DIST / "VoiceAssistant" / "VoiceAssistant.exe"
    if not exe.exists():
        exe = DIST / "VoiceAssistant" / "VoiceAssistant"
    if not exe.exists():
        print("Executable not found. Run build first.")
        return

    print(f"Testing: {exe}")
    result = subprocess.run([str(exe), "--help"], capture_output=True, text=True, timeout=30)
    print("STDOUT:", result.stdout)
    print("STDERR:", result.stderr)
    print("Return code:", result.returncode)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Build Voice Assistant executable")
    parser.add_argument("--clean", action="store_true", help="Remove build artefacts")
    parser.add_argument("--test",  action="store_true", help="Test the built executable")
    args = parser.parse_args()

    if args.clean:
        clean()
    elif args.test:
        test_exe()
    else:
        build()
